{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passage Reranking with Permutation Self-Consistency\n",
    "\n",
    "This notebook implements the passage reranking experiment from the paper \"Found in the Middle: Permutation Self-Consistency Improves Listwise Ranking in Large Language Models\" (arXiv:2310.07712).\n",
    "\n",
    "We use MS MARCO collection with TREC DL19/DL20 evaluation sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Global Inputs**\n",
    "- Set your OpenAI API key here. If you're using Azure, see the code documentation for `OpenAIConfig` for how to modify it.\n",
    "- Set the aggregate size here. The paper uses 20 permutations for passage reranking.\n",
    "- Choose which TREC track to evaluate (DL19 or DL20).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = ''\n",
    "api_type = 'openai'  # or 'azure'\n",
    "num_aggregates = 20  # number of permutations (paper uses 20 for passage reranking)\n",
    "num_limit = 10  # number of queries to process (set to 200 for full DL19/DL20; 10 for testing)\n",
    "track = 'dl19'  # 'dl19' or 'dl20'\n",
    "\n",
    "# Force reload permsc module to pick up code changes\n",
    "import importlib\n",
    "import sys\n",
    "if 'permsc' in sys.modules:\n",
    "    importlib.reload(sys.modules['permsc'])\n",
    "if 'permsc.data' in sys.modules:\n",
    "    importlib.reload(sys.modules['permsc.data'])\n",
    "if 'permsc.aggregator' in sys.modules:\n",
    "    importlib.reload(sys.modules['permsc.aggregator'])\n",
    "if 'permsc.aggregator.exact' in sys.modules:\n",
    "    importlib.reload(sys.modules['permsc.aggregator.exact'])\n",
    "if 'permsc.aggregator.utils' in sys.modules:\n",
    "    importlib.reload(sys.modules['permsc.aggregator.utils'])\n",
    "if 'permsc.evaluation' in sys.modules:\n",
    "    importlib.reload(sys.modules['permsc.evaluation'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "# Fix for multiprocessing in Jupyter notebooks on macOS\n",
    "# Set start method to 'fork' if available, otherwise 'spawn'\n",
    "try:\n",
    "    mp.set_start_method('fork', force=True)\n",
    "except RuntimeError:\n",
    "    # Already set, or 'fork' not available (Windows)\n",
    "    pass\n",
    "\n",
    "from permsc import (\n",
    "    RelevanceRankingPromptBuilder,\n",
    "    OpenAIPromptPipeline,\n",
    "    OpenAIConfig,\n",
    "    ChatCompletionPool,\n",
    "    KemenyOptimalAggregator,\n",
    "    MSMarcoDataset,\n",
    "    ndcg_at_k,\n",
    "    mrr_at_k\n",
    ")\n",
    "\n",
    "config = OpenAIConfig(model_name='gpt-3.5-turbo', api_key=api_key, api_type=api_type)\n",
    "builder = RelevanceRankingPromptBuilder()\n",
    "pool = ChatCompletionPool([config] * 5)  # 5 parallel instances\n",
    "pipeline = OpenAIPromptPipeline(builder, pool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 200 queries\n",
      "First query: which amendment protects a person from cruel or unusual punishment...\n",
      "First query has 100 passages\n"
     ]
    }
   ],
   "source": [
    "# Load dataset based on selected track\n",
    "if track == 'dl19':\n",
    "    ds = MSMarcoDataset(\n",
    "        collection_path='../data/msmarco/collection.tsv',\n",
    "        queries_path='../data/trec-dl19/msmarco-test2019-queries.tsv',\n",
    "        qrels_path='../data/trec-dl19/2019qrels-pass.txt',\n",
    "        top1000_path='../data/trec-dl19/msmarco-passagetest2019-top1000.tsv',\n",
    "        max_passages=100\n",
    "    )\n",
    "elif track == 'dl20':\n",
    "    ds = MSMarcoDataset(\n",
    "        collection_path='../data/msmarco/collection.tsv',\n",
    "        queries_path='../data/trec-dl20/msmarco-test2020-queries.tsv',\n",
    "        qrels_path='../data/trec-dl20/2020qrels-pass.txt',\n",
    "        top1000_path='../data/trec-dl20/msmarco-passagetest2020-top1000.tsv',\n",
    "        max_passages=100\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"Unknown track: {track}\")\n",
    "\n",
    "print(f\"Dataset loaded: {len(ds)} queries\")\n",
    "print(f\"First query: {ds[0].query.content[:80]}...\")\n",
    "print(f\"First query has {len(ds[0].hits)} passages\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def run_passage_reranking_pipeline(pipeline, dataset, num_aggregates, limit=100):\n",
    "    \"\"\"\n",
    "    Run permutation self-consistency pipeline for passage reranking.\n",
    "    \n",
    "    Returns:\n",
    "        prefs_list: List of preference arrays (one per query, each with num_aggregates permutations)\n",
    "        perms_list: List of permutation arrays (input permutations used)\n",
    "        qrels_dict: Dictionary mapping query_id to qrels dict\n",
    "    \"\"\"\n",
    "    prefs_list = []\n",
    "    perms_list = []\n",
    "    qrels_dict = {}\n",
    "    \n",
    "    for example in dataset[:limit]:\n",
    "        example = deepcopy(example)\n",
    "        query_id = example.metadata.get('query_id')\n",
    "        qrels_dict[query_id] = example.metadata.get('qrels', {})\n",
    "        \n",
    "        prefs = []\n",
    "        items = []\n",
    "        perms = []\n",
    "        \n",
    "        # Generate num_aggregates permutations\n",
    "        for _ in range(num_aggregates):\n",
    "            ex_cpy = deepcopy(example)\n",
    "            perm = ex_cpy.randomize_order()\n",
    "            perms.append(perm)\n",
    "            items.append(ex_cpy)\n",
    "        \n",
    "        # Run pipeline\n",
    "        outputs = pipeline.run(items, temperature=0, request_timeout=30)\n",
    "        \n",
    "        # Restore preferences to original order\n",
    "        for output, perm_example in zip(outputs, items):\n",
    "            # Use the permuted example's restore method\n",
    "            restored_prefs = perm_example.permuted_preferences_to_original_order(output)\n",
    "            # CRITICAL: Convert to int64 to avoid Numba typing errors\n",
    "            if restored_prefs.dtype != np.int64 and restored_prefs.dtype != np.int32:\n",
    "                restored_prefs = restored_prefs.astype(np.int64)\n",
    "            prefs.append(restored_prefs)\n",
    "        \n",
    "        # Ensure the array is int64\n",
    "        prefs_array = np.array(prefs, dtype=np.int64)\n",
    "        prefs_list.append(prefs_array)\n",
    "        perms_list.append(np.array(perms))\n",
    "    \n",
    "    return prefs_list, perms_list, qrels_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_rankings(prefs_list):\n",
    "    \"\"\"Aggregate multiple preference rankings using Kemeny optimal aggregation.\"\"\"\n",
    "    import numpy as np\n",
    "    aggregator = KemenyOptimalAggregator()\n",
    "    results = []\n",
    "    \n",
    "    for prefs in prefs_list:\n",
    "        # CRITICAL: Convert to int64 BEFORE aggregation to avoid Numba typing errors\n",
    "        if not (prefs.dtype == np.int64 or prefs.dtype == np.int32):\n",
    "            prefs = prefs.astype(np.int64)\n",
    "        aggregated = aggregator.aggregate(prefs)\n",
    "        results.append(aggregated)\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_reranking(results, dataset, qrels_dict):\n",
    "    \"\"\"\n",
    "    Evaluate aggregated rankings using nDCG@10 and MRR@10.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with mean metrics and per-query scores\n",
    "    \"\"\"\n",
    "    ndcg_scores = []\n",
    "    mrr_scores = []\n",
    "    \n",
    "    for idx, (result, example) in enumerate(zip(results, dataset)):\n",
    "        query_id = example.metadata.get('query_id')\n",
    "        qrels = qrels_dict.get(query_id, {})\n",
    "        \n",
    "        # Convert result to ranked passage IDs\n",
    "        # Handle both indices (integers) and passage IDs (strings)\n",
    "        if len(result) > 0:\n",
    "            # Check if first element is an integer (index) or string (passage ID)\n",
    "            first_elem = result[0] if not isinstance(result, np.ndarray) else result.flat[0]\n",
    "            if isinstance(first_elem, (int, np.integer)):\n",
    "                # Result contains indices - convert to passage IDs\n",
    "                ranked_passage_ids = [example.hits[i].id for i in result if i != -1 and i < len(example.hits)]\n",
    "            else:\n",
    "                # Result contains passage IDs directly\n",
    "                ranked_passage_ids = [pid for pid in result if pid]\n",
    "        else:\n",
    "            ranked_passage_ids = []\n",
    "        \n",
    "        # Compute metrics\n",
    "        ndcg = ndcg_at_k(ranked_passage_ids, qrels, k=10)\n",
    "        mrr = mrr_at_k(ranked_passage_ids, qrels, k=10)\n",
    "        \n",
    "        ndcg_scores.append(ndcg)\n",
    "        mrr_scores.append(mrr)\n",
    "    \n",
    "    return {\n",
    "        'ndcg@10': np.mean(ndcg_scores),\n",
    "        'mrr@10': np.mean(mrr_scores),\n",
    "        'ndcg_scores': ndcg_scores,\n",
    "        'mrr_scores': mrr_scores\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Permutation Self-Consistency Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline on 10 queries with 20 permutations each...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 10 queries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run pipeline\n",
    "print(f\"Running pipeline on {num_limit} queries with {num_aggregates} permutations each...\")\n",
    "prefs_list, perms_list, qrels_dict = run_passage_reranking_pipeline(\n",
    "    pipeline, ds, num_aggregates, limit=num_limit\n",
    ")\n",
    "print(f\"Completed {len(prefs_list)} queries\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating rankings...\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Users/arul/Documents/diff_psc/venv/lib/python3.10/site-packages/pulp/solverdir/cbc/osx/64/cbc /var/folders/lv/3b31xxlx2vg_ntbjdr6b2rtm0000gn/T/27f8c5f69e0e4c2ea75f92c1ec2155ef-pulp.mps timeMode elapsed branch printingOptions all solution /var/folders/lv/3b31xxlx2vg_ntbjdr6b2rtm0000gn/T/27f8c5f69e0e4c2ea75f92c1ec2155ef-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 5 COLUMNS\n",
      "At line 7 RHS\n",
      "At line 8 BOUNDS\n",
      "At line 10 ENDATA\n",
      "Problem MODEL has 0 rows, 1 columns and 0 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Empty problem - 0 rows, 1 columns and 0 elements\n",
      "Optimal - objective value 0\n",
      "Optimal objective 0 - 0 iterations time 0.002\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.00   (Wallclock seconds):       0.01\n",
      "\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Users/arul/Documents/diff_psc/venv/lib/python3.10/site-packages/pulp/solverdir/cbc/osx/64/cbc /var/folders/lv/3b31xxlx2vg_ntbjdr6b2rtm0000gn/T/e0104d064f3d4bd2842931fb4594f45b-pulp.mps timeMode elapsed branch printingOptions all solution /var/folders/lv/3b31xxlx2vg_ntbjdr6b2rtm0000gn/T/e0104d064f3d4bd2842931fb4594f45b-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 5 COLUMNS\n",
      "At line 7 RHS\n",
      "At line 8 BOUNDS\n",
      "At line 10 ENDATA\n",
      "Problem MODEL has 0 rows, 1 columns and 0 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Empty problem - 0 rows, 1 columns and 0 elements\n",
      "Optimal - objective value 0\n",
      "Optimal objective 0 - 0 iterations time 0.002\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.00   (Wallclock seconds):       0.00\n",
      "\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Users/arul/Documents/diff_psc/venv/lib/python3.10/site-packages/pulp/solverdir/cbc/osx/64/cbc /var/folders/lv/3b31xxlx2vg_ntbjdr6b2rtm0000gn/T/55338b8df6364fbfab1613b69f08330d-pulp.mps timeMode elapsed branch printingOptions all solution /var/folders/lv/3b31xxlx2vg_ntbjdr6b2rtm0000gn/T/55338b8df6364fbfab1613b69f08330d-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 5 COLUMNS\n",
      "At line 7 RHS\n",
      "At line 8 BOUNDS\n",
      "At line 10 ENDATA\n",
      "Problem MODEL has 0 rows, 1 columns and 0 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Empty problem - 0 rows, 1 columns and 0 elements\n",
      "Optimal - objective value 0\n",
      "Optimal objective 0 - 0 iterations time 0.002\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.00   (Wallclock seconds):       0.00\n",
      "\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Users/arul/Documents/diff_psc/venv/lib/python3.10/site-packages/pulp/solverdir/cbc/osx/64/cbc /var/folders/lv/3b31xxlx2vg_ntbjdr6b2rtm0000gn/T/63ed4060c1f642c2b2c19e4f48e4839a-pulp.mps timeMode elapsed branch printingOptions all solution /var/folders/lv/3b31xxlx2vg_ntbjdr6b2rtm0000gn/T/63ed4060c1f642c2b2c19e4f48e4839a-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 5 COLUMNS\n",
      "At line 7 RHS\n",
      "At line 8 BOUNDS\n",
      "At line 10 ENDATA\n",
      "Problem MODEL has 0 rows, 1 columns and 0 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Empty problem - 0 rows, 1 columns and 0 elements\n",
      "Optimal - objective value 0\n",
      "Optimal objective 0 - 0 iterations time 0.002\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.00   (Wallclock seconds):       0.00\n",
      "\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Users/arul/Documents/diff_psc/venv/lib/python3.10/site-packages/pulp/solverdir/cbc/osx/64/cbc /var/folders/lv/3b31xxlx2vg_ntbjdr6b2rtm0000gn/T/a19394a28ba74e5dbf4bb73a18d206ee-pulp.mps timeMode elapsed branch printingOptions all solution /var/folders/lv/3b31xxlx2vg_ntbjdr6b2rtm0000gn/T/a19394a28ba74e5dbf4bb73a18d206ee-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 5 COLUMNS\n",
      "At line 7 RHS\n",
      "At line 8 BOUNDS\n",
      "At line 10 ENDATA\n",
      "Problem MODEL has 0 rows, 1 columns and 0 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Empty problem - 0 rows, 1 columns and 0 elements\n",
      "Optimal - objective value 0\n",
      "Optimal objective 0 - 0 iterations time 0.002\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.00   (Wallclock seconds):       0.00\n",
      "\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Users/arul/Documents/diff_psc/venv/lib/python3.10/site-packages/pulp/solverdir/cbc/osx/64/cbc /var/folders/lv/3b31xxlx2vg_ntbjdr6b2rtm0000gn/T/0a866b90c8664636b6ce6656435b6abc-pulp.mps timeMode elapsed branch printingOptions all solution /var/folders/lv/3b31xxlx2vg_ntbjdr6b2rtm0000gn/T/0a866b90c8664636b6ce6656435b6abc-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 5 COLUMNS\n",
      "At line 7 RHS\n",
      "At line 8 BOUNDS\n",
      "At line 10 ENDATA\n",
      "Problem MODEL has 0 rows, 1 columns and 0 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Empty problem - 0 rows, 1 columns and 0 elements\n",
      "Optimal - objective value 0\n",
      "Optimal objective 0 - 0 iterations time 0.002\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.00   (Wallclock seconds):       0.00\n",
      "\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Users/arul/Documents/diff_psc/venv/lib/python3.10/site-packages/pulp/solverdir/cbc/osx/64/cbc /var/folders/lv/3b31xxlx2vg_ntbjdr6b2rtm0000gn/T/1669de849ee74802a10b51999d2f4901-pulp.mps timeMode elapsed branch printingOptions all solution /var/folders/lv/3b31xxlx2vg_ntbjdr6b2rtm0000gn/T/1669de849ee74802a10b51999d2f4901-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 5 COLUMNS\n",
      "At line 7 RHS\n",
      "At line 8 BOUNDS\n",
      "At line 10 ENDATA\n",
      "Problem MODEL has 0 rows, 1 columns and 0 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Empty problem - 0 rows, 1 columns and 0 elements\n",
      "Optimal - objective value 0\n",
      "Optimal objective 0 - 0 iterations time 0.002\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.00   (Wallclock seconds):       0.00\n",
      "\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Users/arul/Documents/diff_psc/venv/lib/python3.10/site-packages/pulp/solverdir/cbc/osx/64/cbc /var/folders/lv/3b31xxlx2vg_ntbjdr6b2rtm0000gn/T/9a3bcb5334644337828674a37708bfc6-pulp.mps timeMode elapsed branch printingOptions all solution /var/folders/lv/3b31xxlx2vg_ntbjdr6b2rtm0000gn/T/9a3bcb5334644337828674a37708bfc6-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 5 COLUMNS\n",
      "At line 7 RHS\n",
      "At line 8 BOUNDS\n",
      "At line 10 ENDATA\n",
      "Problem MODEL has 0 rows, 1 columns and 0 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Empty problem - 0 rows, 1 columns and 0 elements\n",
      "Optimal - objective value 0\n",
      "Optimal objective 0 - 0 iterations time 0.002\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.00   (Wallclock seconds):       0.00\n",
      "\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Users/arul/Documents/diff_psc/venv/lib/python3.10/site-packages/pulp/solverdir/cbc/osx/64/cbc /var/folders/lv/3b31xxlx2vg_ntbjdr6b2rtm0000gn/T/67a8bab64ef84d0fb45e1f576f574411-pulp.mps timeMode elapsed branch printingOptions all solution /var/folders/lv/3b31xxlx2vg_ntbjdr6b2rtm0000gn/T/67a8bab64ef84d0fb45e1f576f574411-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 5 COLUMNS\n",
      "At line 7 RHS\n",
      "At line 8 BOUNDS\n",
      "At line 10 ENDATA\n",
      "Problem MODEL has 0 rows, 1 columns and 0 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Empty problem - 0 rows, 1 columns and 0 elements\n",
      "Optimal - objective value 0\n",
      "Optimal objective 0 - 0 iterations time 0.002\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.00   (Wallclock seconds):       0.00\n",
      "\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Users/arul/Documents/diff_psc/venv/lib/python3.10/site-packages/pulp/solverdir/cbc/osx/64/cbc /var/folders/lv/3b31xxlx2vg_ntbjdr6b2rtm0000gn/T/3b5b32f37d9049b4a1991685959d5174-pulp.mps timeMode elapsed branch printingOptions all solution /var/folders/lv/3b31xxlx2vg_ntbjdr6b2rtm0000gn/T/3b5b32f37d9049b4a1991685959d5174-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 5 COLUMNS\n",
      "At line 7 RHS\n",
      "At line 8 BOUNDS\n",
      "At line 10 ENDATA\n",
      "Problem MODEL has 0 rows, 1 columns and 0 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Empty problem - 0 rows, 1 columns and 0 elements\n",
      "Optimal - objective value 0\n",
      "Optimal objective 0 - 0 iterations time 0.002\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.00   (Wallclock seconds):       0.00\n",
      "\n",
      "Aggregated 10 rankings\n"
     ]
    }
   ],
   "source": [
    "# Aggregate rankings\n",
    "print(\"Aggregating rankings...\")\n",
    "results = aggregate_rankings(prefs_list)\n",
    "print(f\"Aggregated {len(results)} rankings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Aggregated Results (PSC) ===\n",
      "nDCG@10: 0.0000\n",
      "MRR@10: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate aggregated results\n",
    "metrics = evaluate_reranking(results, ds[:num_limit], qrels_dict)\n",
    "print(f\"\\n=== Aggregated Results (PSC) ===\")\n",
    "print(f\"nDCG@10: {metrics['ndcg@10']:.4f}\")\n",
    "print(f\"MRR@10: {metrics['mrr@10']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with Baseline (First-Stage Retrieval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Baseline (First-Stage Retrieval) ===\n",
      "nDCG@10: 0.0000\n",
      "MRR@10: 0.0000\n",
      "\n",
      "=== Improvement ===\n",
      "nDCG@10 improvement: 0.0000 (nan%)\n",
      "MRR@10 improvement: 0.0000 (nan%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lv/3b31xxlx2vg_ntbjdr6b2rtm0000gn/T/ipykernel_81765/2237042895.py:15: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  print(f\"nDCG@10 improvement: {metrics['ndcg@10'] - baseline_metrics['ndcg@10']:.4f} ({((metrics['ndcg@10'] / baseline_metrics['ndcg@10'] - 1) * 100):.2f}%)\")\n",
      "/var/folders/lv/3b31xxlx2vg_ntbjdr6b2rtm0000gn/T/ipykernel_81765/2237042895.py:16: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  print(f\"MRR@10 improvement: {metrics['mrr@10'] - baseline_metrics['mrr@10']:.4f} ({((metrics['mrr@10'] / baseline_metrics['mrr@10'] - 1) * 100):.2f}%)\")\n"
     ]
    }
   ],
   "source": [
    "# Evaluate baseline (original retrieval order)\n",
    "baseline_results = []\n",
    "for example in ds[:num_limit]:\n",
    "    # Use original retrieval order (passages are already in retrieval order)\n",
    "    # Use indices [0, 1, 2, ...] to represent original order\n",
    "    ranked_indices = list(range(len(example.hits)))\n",
    "    baseline_results.append(ranked_indices)\n",
    "\n",
    "baseline_metrics = evaluate_reranking(baseline_results, ds[:num_limit], qrels_dict)\n",
    "print(f\"\\n=== Baseline (First-Stage Retrieval) ===\")\n",
    "print(f\"nDCG@10: {baseline_metrics['ndcg@10']:.4f}\")\n",
    "print(f\"MRR@10: {baseline_metrics['mrr@10']:.4f}\")\n",
    "\n",
    "print(f\"\\n=== Improvement ===\")\n",
    "print(f\"nDCG@10 improvement: {metrics['ndcg@10'] - baseline_metrics['ndcg@10']:.4f} ({((metrics['ndcg@10'] / baseline_metrics['ndcg@10'] - 1) * 100):.2f}%)\")\n",
    "print(f\"MRR@10 improvement: {metrics['mrr@10'] - baseline_metrics['mrr@10']:.4f} ({((metrics['mrr@10'] / baseline_metrics['mrr@10'] - 1) * 100):.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Run Performance (without aggregation)\n",
    "\n",
    "Compare individual permutation runs to see the benefit of aggregation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual runs nDCG@10: nan ± nan\n",
      "Individual runs MRR@10: nan ± nan\n",
      "\n",
      "Aggregated nDCG@10: 0.0000\n",
      "Aggregated MRR@10: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arul/Documents/diff_psc/venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/arul/Documents/diff_psc/venv/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/arul/Documents/diff_psc/venv/lib/python3.10/site-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/arul/Documents/diff_psc/venv/lib/python3.10/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/Users/arul/Documents/diff_psc/venv/lib/python3.10/site-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "def evaluate_individual_runs(prefs_list, dataset, qrels_dict):\n",
    "    \"\"\"Evaluate each individual permutation run.\"\"\"\n",
    "    num_runs = len(prefs_list[0]) if prefs_list else 0\n",
    "    individual_ndcg = [[] for _ in range(num_runs)]\n",
    "    individual_mrr = [[] for _ in range(num_runs)]\n",
    "    \n",
    "    for idx, (prefs, example) in enumerate(zip(prefs_list, dataset)):\n",
    "        query_id = example.metadata.get('query_id')\n",
    "        qrels = qrels_dict.get(query_id, {})\n",
    "        \n",
    "        for run_idx, pref in enumerate(prefs):\n",
    "            # Convert preference array to ranked passage IDs\n",
    "            ranked_passage_ids = [example.hits[i].id for i in pref if i != -1]\n",
    "            \n",
    "            ndcg = ndcg_at_k(ranked_passage_ids, qrels, k=10)\n",
    "            mrr = mrr_at_k(ranked_passage_ids, qrels, k=10)\n",
    "            \n",
    "            individual_ndcg[run_idx].append(ndcg)\n",
    "            individual_mrr[run_idx].append(mrr)\n",
    "    \n",
    "    return {\n",
    "        'ndcg': [np.mean(scores) for scores in individual_ndcg],\n",
    "        'mrr': [np.mean(scores) for scores in individual_mrr]\n",
    "    }\n",
    "\n",
    "individual_metrics = evaluate_individual_runs(prefs_list, ds[:num_limit], qrels_dict)\n",
    "print(f\"Individual runs nDCG@10: {np.mean(individual_metrics['ndcg']):.4f} ± {np.std(individual_metrics['ndcg']):.4f}\")\n",
    "print(f\"Individual runs MRR@10: {np.mean(individual_metrics['mrr']):.4f} ± {np.std(individual_metrics['mrr']):.4f}\")\n",
    "print(f\"\\nAggregated nDCG@10: {metrics['ndcg@10']:.4f}\")\n",
    "print(f\"Aggregated MRR@10: {metrics['mrr@10']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
